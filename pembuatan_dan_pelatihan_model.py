# -*- coding: utf-8 -*-
"""Pembuatan dan Pelatihan Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DCLMlwYxMtd1SSV7P9nS3nOXQi7NYfMt

**Lakukan Import**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.multioutput import ClassifierChain
from sklearn.linear_model import LogisticRegression
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline  # Pipeline khusus imblearn (bukan sklearn!)
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MultiLabelBinarizer
from ipywidgets import widgets, VBox, Button, Output
from IPython.display import display
from collections import defaultdict
import joblib

"""**load data hasil clustering**"""

df = pd.read_csv("hasil_clutering_iklan.csv")
print(df.head())

df

df.info()

"""**medeteksi kategorikal dan menyesuikan one-hot encoding pada data categorical**"""

categorical_list = [
    "Ad Placement Method",
    "Type of Media (MOECM)",
    "Outlet Channel (Agency submission)",
    "Language",
    "Purpose"
]

for column in categorical_list:
    df[column] = df[column].str.lower()

df

df["Cluster"].unique()

for column in categorical_list:
    print(df[column].unique())

import pandas as pd
import numpy as np

categorical_list = [
    "Ad Placement Method",
    "Type of Media (MOECM)",
    "Outlet Channel (Agency submission)",
    "Language",
    "Purpose"
]

# Fungsi bantu untuk membersihkan dan memisahkan nilai gabungan
def split_and_clean(value):
    if pd.isna(value):
        return []
    if isinstance(value, str):
        value = value.lower()
        separators = ['|', '/', ',', '&', ';', '\\']
        for sep in separators:
            value = value.replace(sep, ',')
        return [v.strip() for v in value.split(',') if v.strip()]
    else:
        return [str(value).strip().lower()]

# Fungsi untuk membersihkan nilai cluster (dianggap integer)
def split_cluster(value):
    if pd.isna(value):
        return []
    if isinstance(value, str):
        separators = ['|', '/', ',', '&', ';', '\\']
        for sep in separators:
            value = value.replace(sep, ',')
        return [int(v.strip()) for v in value.split(',') if v.strip().isdigit()]
    elif isinstance(value, (list, np.ndarray)):
        return [int(v) for v in value]
    else:
        return [int(value)]

options_dict = {}

encoded_df = pd.DataFrame(index=df.index)

# Encode kategori
for column in categorical_list:
    all_values = df[column].apply(split_and_clean)
    unique_labels = sorted(set(label for sublist in all_values for label in sublist))
    options_dict[column] = unique_labels

    for label in unique_labels:
        encoded_df[f"{column}__{label}"] = all_values.apply(lambda x: int(label in x))

# Multi-label encoding untuk Cluster
cluster_values = df["Cluster"].apply(split_cluster)
unique_clusters = sorted(set(c for sublist in cluster_values for c in sublist))

for cluster in unique_clusters:
    encoded_df[f"Cluster__{cluster}"] = cluster_values.apply(lambda x: int(cluster in x))

# (Optional) Print info
print("Label unik dalam 'Cluster':", unique_clusters)

encoded_df["Spend Amount"] = df["Spend Amount"].fillna(0)

"""**menampilakan data hasil encoding**"""

encoded_df

encoded_df = encoded_df.sample(frac=1, random_state=42).reset_index(drop=True)

split_index = int(0.8 * len(encoded_df))

df_train = encoded_df[:split_index]
df_test = encoded_df[split_index:]

"""**melakukan split data untuk pelatihan model secara terpisah**"""

encoded_df_0 = df_train.drop(columns=["Cluster__1", "Cluster__2"])
encoded_df_1 = df_train.drop(columns=["Cluster__0", "Cluster__2"])
encoded_df_2 = df_train.drop(columns=["Cluster__1", "Cluster__0"])

"""**model_0**"""

X = encoded_df_0.drop(columns="Cluster__0") # Ganti dengan kolom fitur Anda
y = encoded_df_0['Cluster__0']  # Ganti dengan kolom target Anda

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)

print("Distribusi kelas asli:", Counter(y))

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

base_model_0 = LogisticRegression(solver='lbfgs', max_iter=1000)
base_model_0.fit(X_train, y_train)

y_pred = base_model_0.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model 0: {accuracy}")

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))  # Atur ukuran gambar
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['0', '1'], yticklabels=['0', '1'])  # Ganti label jika perlu
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Model 0')
plt.show()

"""**model 1**"""

X = encoded_df_1.drop(columns="Cluster__1") # Ganti dengan kolom fitur Anda
y = encoded_df_1['Cluster__1']  # Ganti dengan kolom target Anda

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)

print("Distribusi kelas asli:", Counter(y))

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

base_model_1 = LogisticRegression(solver='lbfgs', max_iter=1000)
base_model_1.fit(X_train, y_train)

y_pred = base_model_1.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model 1: {accuracy}")

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))  # Atur ukuran gambar
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['0', '1'], yticklabels=['0', '1'])  # Ganti label jika perlu
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Model 1')
plt.show()

"""**model 2**"""



X = encoded_df_2.drop(columns="Cluster__2") # Ganti dengan kolom fitur Anda
y = encoded_df_2['Cluster__2']  # Ganti dengan kolom target Anda

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)

print("Distribusi kelas asli:", Counter(y_resampled))

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

base_model_2 = LogisticRegression(solver='lbfgs', max_iter=1000)
base_model_2.fit(X_train, y_train)

y_pred = base_model_2.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model 2: {accuracy}")

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))  # Atur ukuran gambar
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
               xticklabels=['0', '1'], yticklabels=['0', '1'])  # Ganti label jika perlu
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Model 2')
plt.show()

"""**mengabungkan model**"""

df_test

"""**melakukan uji pada gabungan model**"""

y_true = df_test[['Cluster__0', 'Cluster__1', 'Cluster__2']].values

y_pred_0 = base_model_0.predict(df_test.drop(columns=['Cluster__0', 'Cluster__1', 'Cluster__2']))
y_pred_1 = base_model_1.predict(df_test.drop(columns=['Cluster__0', 'Cluster__1', 'Cluster__2']))
y_pred_2 = base_model_2.predict(df_test.drop(columns=['Cluster__0', 'Cluster__1', 'Cluster__2']))

y_pred = np.column_stack((y_pred_0, y_pred_1, y_pred_2))

y_pred = [[int(val) for val in row] for row in y_pred]

print(y_pred)

import numpy as np

# Asumsi y_true dan y_pred adalah array numpy dengan bentuk (n_samples, 3)
y_true_real = np.argmax(y_true, axis=1)
y_pred_real = np.argmax(y_pred, axis=1)

print(y_true_real)

accuracy = accuracy_score(y_true_real, y_pred_real)
precision = precision_score(y_true, y_pred, average='weighted') # atau 'micro', 'macro'
recall = recall_score(y_true, y_pred, average='weighted') # atau 'micro', 'macro'
f1 = f1_score(y_true, y_pred, average='weighted') # atau 'micro', 'macro'

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


cm = confusion_matrix(y_true_real, y_pred_real)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""**save model input**"""

joblib.dump(base_model_0, 'base_model_0.pkl')


joblib.dump(base_model_1, 'base_model_1.pkl')


joblib.dump(base_model_2, 'base_model_2.pkl')

"""**mencoba melakukan uji coba bisa juga di lihat di app.py**"""

# all_columns = encoded_df.drop(columns=['Cluster__0', 'Cluster__1', 'Cluster__2']).columns.tolist()
# print(all_columns)

# grouped_features = defaultdict(list)
# for f in all_columns:
#     if '__' in f:
#         key, val = f.split('__', 1)
#         grouped_features[key.strip()].append(val.strip())

# # Menampilkan hasil
# for k, v in grouped_features.items():
#     print(f"{k} ({len(v)} items):")
#     print(v)
#     print()

# opsi_apm =  grouped_features["Ad Placement Method"]
# opsi_type_of_media = grouped_features["Type of Media (MOECM)"]
# opsi_outlet_channel = grouped_features["Outlet Channel (Agency submission)"]
# opsi_language = grouped_features["Language"]
# opsi_purpose = grouped_features["Purpose"]

# for i in range(len(opsi_apm)):
#      print(f"{i+1}. {opsi_apm[i]}")
# Ad_Placement_Method = input("Ad Placement Method: ")
# a = f"Ad Placement Method__{Ad_Placement_Method.lower()}"
# for i in range(len(opsi_type_of_media)):
#      print(f"{i+1}. {opsi_type_of_media[i]}")
# Type_of_Media = input("Type of Media (MOECM): ")
# b = f"Type of Media (MOECM)__{Type_of_Media.lower()}"
# for i in range(len(opsi_outlet_channel)):
#      print(f"{i+1}. {opsi_outlet_channel[i]}")
# Outlet_Channel = input("Outlet Channel (Agency submission): ")
# c = f"Outlet Channel (Agency submission)__{Outlet_Channel.lower()}"
# for i in range(len(opsi_language)):
#      print(f"{i+1}. {opsi_language[i]}")
# Language = input("Language: ")
# d = f"Language__{Language.lower()}"
# for i in range(len(opsi_purpose)):
#      print(f"{i+1}. {opsi_purpose[i]}")
# Purpose = input("Purpose: ")
# e = f"Purpose__{Purpose.lower()}"
# Spend_Amount = input("Spend Amount: ")

# selected_features = {a, b, c, d, e}
# feature = [1 if i in selected_features else 0 for i in all_columns]

# print(Spend_Amount)

# feature[-1] = (float(Spend_Amount))

# feature_list = []
# feature_list.append(feature)

# print(feature_list)

# len(all_columns)

# len(feature_list[0])

# X_input = np.array(feature_list)

# print(X_input)

# y_pred_0 = base_model_0.predict(X_input)
# y_pred_1 = base_model_1.predict(X_input)
# y_pred_2 = base_model_2.predict(X_input)

# # Gabungkan hasil prediksi menjadi multi-label
# y_pred = np.column_stack((y_pred_0, y_pred_1, y_pred_2))

# # Konversi ke list of lists of int
# y_pred = [[int(val) for val in row] for row in y_pred]

# y_pred_ku = np.argmax(y_pred, axis=1)

# print(y_pred_ku)